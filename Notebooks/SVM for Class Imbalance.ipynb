{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM for Class Imbalance with Scikit-Learn\n",
    "\n",
    "Kaggle CreditCard Fraud Detection Data can be downloaded here:\n",
    "https://github.com/nsethi31/Kaggle-Data-Credit-Card-Fraud-Detection/blob/master/creditcard.csv?raw=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How SVM Works:\n",
    "Part 1: https://www.youtube.com/watch?v=-3URiBiFgIg\n",
    "        \n",
    "Part 2: https://www.youtube.com/watch?v=BomqrcbJS4g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Split data into train and test splits\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# retrieve numpy array\n",
    "data = data.values\n",
    "# split into input and output elements\n",
    "X, y = data[:, 1:-1], data[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many unique values of each class\n",
    "\n",
    "import numpy as np\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The class weighing can be defined multiple ways; for example:\n",
    "\n",
    "* Domain expertise, determined by talking to subject matter experts\n",
    "* Tuning, determined by a hyperparameter search such as a grid search\n",
    "* Heuristic, specified using a general best practice\n",
    "* A best practice for using the class weighting is to use the inverse of the class distribution present in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate heuristic class weighting\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# calculate class weighting according to training data\n",
    "weighting = compute_class_weight('balanced', [0,1], y_train)\n",
    "print(weighting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting C for SVM:\n",
    "The weight is defined proportional to the class distribution:\n",
    "\n",
    "$C_i = weight_i * C$\n",
    "\n",
    "A larger weighting can be used for the minority class, allowing the margin to be softer, whereas a smaller weighting can be used for the majority class, forcing the margin to be harder and preventing misclassified examples.\n",
    "\n",
    "* *Small Weight:* Smaller C value, larger penalty for misclassified examples.\n",
    "* *Larger Weight:* Larger C value, smaller penalty for misclassified examples.\n",
    "\n",
    "This has the effect of encouraging the margin to contain the majority class with less flexibility, but allow the minority class to be flexible with misclassification of majority class examples onto the minority class side if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell can take long to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "weights = {0:weighting[0], 1:weighting[1]} \n",
    "print(weights)\n",
    "# define model\n",
    "# try with class_weight=weights and class_weight=None\n",
    "model = SVC(probability=True)\n",
    "#model = SVC(class_weight=weights, probability=True)\n",
    "#model = SVC(gamma='scale', class_weight='balanced', probability=True)\n",
    "\n",
    "# fit a model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "pos_probs = probs[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_test, pos_probs)\n",
    "\n",
    "# summarize performance\n",
    "print(' ROC AUC = %.3f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# prepare train and test dataset\n",
    "def prepare_data(n_samples=1000):\n",
    "    # generate 2d classification dataset\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=3, n_redundant=0,\n",
    "    n_clusters_per_class=2, weights=[0.99], flip_y=0, random_state=4)\n",
    "    # split into train and test\n",
    "    n_train = n_samples//2\n",
    "    trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "    trainy, testy = y[:n_train], y[n_train:]\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "# prepare dataset\n",
    "X_train, y_train, X_test, y_test = prepare_data()\n",
    "\n",
    "# calculate class weighting according to training data\n",
    "weighting = compute_class_weight('balanced', [0,1], y_train)\n",
    "weights = {0:weighting[0], 1:weighting[1]} \n",
    "print(weights)\n",
    "\n",
    "# define model\n",
    "# try with class_weight=weights and class_weight=None\n",
    "#model = SVC(probability=True)\n",
    "#model = SVC(class_weight=weights, probability=True)\n",
    "model = SVC(gamma='scale', class_weight='balanced', probability=True)\n",
    "\n",
    "# fit a model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "pos_probs = probs[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_test, pos_probs)\n",
    "\n",
    "# summarize performance\n",
    "print(' ROC AUC = %.3f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
